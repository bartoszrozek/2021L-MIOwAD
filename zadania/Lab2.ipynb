{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Niestety nie udało mi się zaimplementować PWB, poprawiłem strukturę klasy i zaimplementowałem dwie metody losowania wag (w tym Xavier). Z PWB udało mi się jedynie uzyskać macierz A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "#korzystam z biblioteki np, aby x mogl byc wektorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pochodna funkcji aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_der(x):\n",
    "    return np.exp(-x)/(1+np.exp(-x))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, weights, activation_function, activation_function_der, neurons, inputs, outputs):\n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_der = activation_function_der\n",
    "        self.neurons = neurons\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        if weights is None:\n",
    "            self.weights_random()\n",
    "        elif weights == \"Xavier\": \n",
    "            self.weights_xavier()\n",
    "        else:\n",
    "            self.weights = weights\n",
    "    \n",
    "    def weights_random(self):\n",
    "        self.weights = [None for i in range (len(self.neurons)+1)]\n",
    "        \n",
    "        self.weights[0] = np.random.random((self.inputs + 1, self.neurons[0]))\n",
    "        self.weights[-1] = np.random.random((self.neurons[-1] + 1, self.outputs))\n",
    "        \n",
    "        for i in range(len(self.neurons) - 1):\n",
    "            self.weights[i+1] = np.random.random((self.neurons[i]+1, self.neurons[i+1]))\n",
    "    \n",
    "    def weights_xavier(self):\n",
    "        xavier = np.sqrt(6)/np.sqrt(self.inputs+self.outputs)\n",
    "        self.weights = [None for i in range (len(self.neurons)+1)]\n",
    "        \n",
    "        self.weights[0] = np.random.random((self.inputs + 1, self.neurons[0]))\n",
    "        self.weights[-1] = np.random.random((self.neurons[-1] + 1, self.outputs))\n",
    "        \n",
    "        for i in range(len(self.neurons) - 1):\n",
    "            self.weights[i+1] = np.random.random((self.neurons[i]+1, self.neurons[i+1]))\n",
    "        \n",
    "        self.weights = [weight * 2 * xavier - xavier for weight in self.weights]\n",
    "            \n",
    "    def predict(self, inp):\n",
    "        A = self.forward(inp)\n",
    "        return(A[-1])\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        if inp.ndim == 1:\n",
    "            inp = inp[None]\n",
    "        #tworzenie macierzy w przypadku wektora\n",
    "        \n",
    "        v = inp      \n",
    "        A = []\n",
    "        for weight in self.weights:\n",
    "            v = np.concatenate( [v, np.ones((v.shape[0],1))], axis = 1)\n",
    "            A.append(v)\n",
    "            prediction = v @ weight\n",
    "            v = self.activation_function(prediction)\n",
    "            A.append(prediction)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, inp, y, eta):\n",
    "        A = self.forward(inp)\n",
    "        E = np.zeros(A.shape)\n",
    "        v = A[-1,]\n",
    "        v = v[v != 0]\n",
    "        E[k-1,0:len(v)] = (sigmoid(v) - y) * sigmoid_der(A[k-1,0:len(v)])\n",
    "\n",
    "        for i in reversed(range (k-1)):\n",
    "            for j in range (self.weights[i].shape[1]):\n",
    "                E[i, j] = sigmoid_der(A[i,j]) * sum(self.weights[i+1][i,q] * E[i+1,j]  for q in range(self.weights[i+1].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('mio1/regression/square-simple-training.csv', index_col=0)\n",
    "test_df = pd.read_csv('mio1/regression/square-simple-test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.]]),\n",
       " array([[-2.43792681,  1.78248173, -1.31409643,  0.23014844,  1.61023192]]),\n",
       " array([[0.08032593, 0.85600304, 0.21180217, 0.55728448, 0.83344358,\n",
       "         1.        ]]),\n",
       " array([[ 2.60894835, -2.8062801 ,  1.81877229, -3.39449793, -0.94113279]]),\n",
       " array([[0.93143526, 0.05698575, 0.86041875, 0.03246786, 0.28067158,\n",
       "         1.        ]]),\n",
       " array([[2.75860478]])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MLP(activation_function = sigmoid,activation_function_der = sigmoid_der, neurons = [5,5], inputs = 1, outputs = 1, weights=\"Xavier\")\n",
    "model1.forward(np.array([1])[None].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
